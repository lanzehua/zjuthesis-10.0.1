\cleardoublepage
\chapternonum{摘要}

\setlength{\parindent}{2em} 
近年来，艺术风格迁移作为一种通过将风格注入到内容载体中来创建视觉上吸引人的图像的方法越来越受欢迎。风格迁移技术，作为一种将特定艺术风格应用到图像或视频内容中的技术，已经成为数字艺术创作的重要工具，风格迁移用途广泛，能应用到2D图像上，也可以应用到3D场景上。它允许艺术家和设计师将传统绘画、摄影及其他视觉艺术的风格应用到数字作品中，创造出独特的视觉效果。这种技术不仅丰富了艺术创作手段，也为艺术表达提供了新可能性。一个艺术风格图之所以能够被人眼鉴定为真，而生成的风格化结果不能，究其原因，在于现有的2D风格迁移方法不能在生成无伪影的高质量图像的同时充分兼顾如颜色，笔触，色调，纹理等艺术特征。与此同时，现有的3D场景风格迁移技术，均不同程度地存在一些问题：多视角一致性不够、对任意一个新风格图片都需要重新进行风格化训练、对算力要求较高、训练推理速度较慢等。针对上述问题，本文设计了一个新的2D图像任意风格迁移算法，并提出了一个支持不同风格迁移方法的零样本3D场景快速风格迁移框架。具体工作主要包括以下两个方面：
\newline \indent（1）提出一种基于风格一致性实例归一化和对比学习的2D图像任意风格迁移算法。其中风格一致性实例归一化 (SCIN)模块用来捕获远程和非本地风格相关性。这可以将内容特征与风格特征对齐；基于实例的对比学习(ICL)方法用来学习风格化到风格化的关系并消除伪影；并且我们提出了一个新的感知编码器(PE)，它可以捕获风格信息，避免模型过多关注风格图像的显著分类特征。   
\newline \indent（2）提出一种基于超网络和可变3D高斯点的零样本三维场景风格迁移框架。该框架支持通过即插即用的方式使用任意的2D风格迁移方法作为3D场景风格迁移的指导，并且使用3DGS的方法作为3D建模表示的方法，风格图特征将通过特别训练的超网络和变形网络对3DGS的外层高斯点的部分颜色属性表达进行一些调整，在保证快速训练快速渲染的同时实现较高的多视角一致性。
\newline
{\addfontfeatures{FakeBold=2.0}\textbf{关键词:}}
任意风格迁移；3D高斯飞溅；零样本推理；超网络 

\cleardoublepage
\chapternonum{Abstract}
In recent years, art style transfer has gained popularity as a way to create visually appealing images by injecting style into content images. Style transfer technology, as a technology that applies a specific artistic style to the image or video content, has become an important tool for digital art creation. Style transfer is widely used, and can be applied to 2D images and 3D scenes. It allows artists and designers to apply styles from traditional painting, photography or other visual arts to digital works to create unique visual effects. This technology not only enriches the means of artistic creation, but also provides new possibilities for artistic expression. The reason why an artistic style image can be identified as true by the human eye, while the resulting stylistic images cannot, is that the existing 2D style transfer methods cannot fully take the artistic characteristics such as color, brush stroke, tone, texture and so on into account while producing a high-quality image without artifacts. Meanwhile, the existing 3D scene style transfer technology has some problems to varying degrees: there are still some issues with multi-view consistency, and during stylization inference, it needs to be retrained for each new style image, high computing power requirements, slow training speed and reasoning speed etc. To solve the problems mentioned above, this paper designs a new algorithm for arbitrary style transfer of 2D images, and proposes a fast style transfer framework for zero-shot 3D scenes that supports different 2D image style transfer methods. The specific work mainly includes the following two aspects:
\newline \indent(1) A 2D image arbitrary style transfer algorithm based on Style Consistency Instance Normalization (SCIN) and Instance-based Contrast Learning (ICL) is proposed. The SCIN module is used to capture remote and non-local style correlations. This aligns content features with style features; ICL is used to learn stylized-to-stylized relationships and eliminate artifacts while processing. We also propose a new Perceptual Encoder (PE), which can capture style information and avoid models from focusing too much on the salient classification features of style images.
\newline \indent(2) A zero-shot 3D scene style transfer framework based on hyper network and deformable 3D Gaussian splatting is proposed. The framework supports the use of any 2D arbitary style transfer method as a guide for 3D scene style transfer in a plug-and-play manner, and the method of 3DGS is used as the way of 3D modeling representation. The style map features will make some adjustments to the expression of some color attributes of the outer Gaussian points through specially trained hyper networks and deformable MLPs, so as to achieve high multi-view consistency while ensuring fast training and fast rendering process.
\newline
{\addfontfeatures{FakeBold=2.0}\textbf{Keywords:}} 
Arbitrary Style Transfer; 3D Gaussian Splatting; Zero-Shot Inference; Hyper Network 
